{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced24d22",
   "metadata": {},
   "source": [
    "# Backend.AI 체험하기\n",
    "### pytorch version (Custom)\n",
    "DATASET : FashionMNIST\n",
    "MODEL : LeNET\n",
    "\n",
    "### Improve performance\n",
    "1. Change Hyper Parameters\n",
    "2. Change Model DNN -> CNN (use GPU in Backend.AI cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "37684062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = {\n",
    "    'batch_size' : 64,\n",
    "    'lr':0.01,\n",
    "    'n_classes' : 10,\n",
    "    'epochs':5,\n",
    "    'mean':0.5, \n",
    "    'std':0.5,\n",
    "    'device': 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0a58c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# 간단한 transform 정의\n",
    "'''\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((config['mean']), (config['std']))])\n",
    "\n",
    "\n",
    "'''\n",
    "# dataset & dataLoader\n",
    "'''\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c644caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9: 6000, 0: 6000, 3: 6000, 2: 6000, 7: 6000, 5: 6000, 1: 6000, 6: 6000, 4: 6000, 8: 6000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# class balance 조사\n",
    "\n",
    "balance good!!\n",
    "\n",
    "'''\n",
    "class_dict = {}\n",
    "for _class in trainset.targets:\n",
    "    _class = _class.item()\n",
    "    if _class not in class_dict:\n",
    "        class_dict[_class]=0\n",
    "    class_dict[_class]+=1\n",
    "print(class_dict)\n",
    "config['n_classes'] = len(class_dict.keys())\n",
    "config['n_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cf9fdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODEL 정의\n",
    "tensorflow 예제에서는 단순 DNN이였다면 \n",
    "퍼포먼스 향상을 위해 CNN(LeNet)으로 change\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_classes = 1):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,kernel_size = 1) # 28 x 28 이므로 5->1로 변경\n",
    "        self.conv2 = nn.Conv2d(6,16,kernel_size = 5)\n",
    "        self.conv3 = nn.Conv2d(16,120,kernel_size = 5)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, n_classes)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride =2)\n",
    "        \n",
    "    def forward(self, x): # tanh -> relu\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1,120)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0035a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train, valdation function\n",
    "'''\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    running_loss = 0\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    running_loss /= len(dataloader)\n",
    "    return running_loss\n",
    "\n",
    "def validation(model, dataloader, criterion, device):\n",
    "    running_loss = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        preds += torch.argmax(outputs,1).tolist()\n",
    "        targets += labels.tolist()\n",
    "        running_loss += loss.item()\n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    score = (preds == targets).sum() / len(preds)\n",
    "    running_loss /= len(dataloader)\n",
    "    return running_loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c71389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:23<00:00, 39.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 46.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 0.396 \t test_loss : 0.337 \t score : 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:20<00:00, 44.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 0.344 \t test_loss : 0.326 \t score : 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:25<00:00, 37.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:16<00:00, 56.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 0.316 \t test_loss : 0.286 \t score : 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:24<00:00, 38.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 938/938 [00:19<00:00, 48.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 0.299 \t test_loss : 0.278 \t score : 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(config['n_classes']).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = config['lr'])\n",
    "epochs = config['epochs']\n",
    "device = config['device']\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    t_loss = train(model, trainloader, criterion, optimizer, device)\n",
    "    v_loss, score = validation(model, testloader, criterion, device)\n",
    "    print('train_loss : {:.4f} \\t test_loss : {:.4f} \\t score : {:.3f}'.format(t_loss, v_loss, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score : {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe5abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
